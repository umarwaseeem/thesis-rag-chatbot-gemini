{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG Masters Thesis Chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i200762\n",
    "\n",
    "Muhammad Umar Waseem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "import pickle\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.document_loaders import UnstructuredExcelLoader\n",
    "from langchain.vectorstores.faiss import FAISS\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_retrieval_chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google API Key already set from env\n"
     ]
    }
   ],
   "source": [
    "if \"GOOGLE_API_KEY\" not in os.environ:\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Provide your Google API Key\")\n",
    "else:\n",
    "    print(\"Google API Key already set from env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\", google_api_key=os.environ[\"GOOGLE_API_KEY\"])\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = UnstructuredExcelLoader(\"dataset.xlsx\")\n",
    "docs = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "264\n"
     ]
    }
   ],
   "source": [
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S. #\n",
      "Thesis Title and Access Link (to PDF Report)\n",
      "Link to the MS Thesis Report\n",
      "Thesis Abstract\n",
      "\n",
      "\n",
      "1\n",
      "21I-2191 Laraib Afzal\\n\\n\\n\\nProsodic alignment for Automatic dubbing\\n\\n\n",
      "https://drive.google.com/file/d/11nobbbLcTsNzHQHrs5mscGYP1bQ487wM/view?usp=drive_link\n",
      "Automatic dubbing is the process of replacing the audio track of a video with a different language. In automatic dubbing, prosodic alignment is used to match the suprasegmental features like timbre, prosody, duration, pauses and intonation of the original speech with synthesed speech, in order to produce a natural-sounding dubbed video. This is done by analyzing and mapping these features of the original and translated speech. Existing research on automatic dubbing lack to addresses these features in source video which impact the overall naturalness and fluency of Synthesized speech. To solve this we proposed end-to-end architecture, following modular approach, to generate high quality dubbed video. In this research, we mainly focus on TTS module by considering mentioned features for prosodic alignment in generated speech with synchronization of original utterance. We train our model learn to predict the suprasegmental features of the input voice and generate synthesized speech that matches the pattern of stress and intonation of the input voice. This help our proposed model to create a more natural and coherent output and improve the overall accuracy of end to end architecture. We explore auto-regressive decoder models and Constructive voice-voice pre-training model for our TTS module. We used a common voice English dataset which contains English text and corresponding voices. To evaluate our model we perform Quantitative Evaluation by calculating Mel Cepstral Distortion (MCD) with Dynamic Time Warping (DTW) and Word Error Rate.\n",
      "\n",
      "\n",
      "2\n",
      "21I-2195 Ansa Liaqat\\n\\n\\nBoundary-Aware Multiscale Brain Tumor Segmentation \\nwith a Compact Model using Spatial Pyramid Pooling\n",
      "https://drive.google.com/file/d/1bJk975FfhADylaYi1lEy_AixFk73FAeJ/view?usp=drive_link\n",
      "One of the most difficult tasks in medical image analysis is brain tumor segmentation. To accurately delineate the regions of brain tumors is the aim of brain tumor segmentation. Deep learning techniques have recently shown promising results in resolving a variety of computer vision problems, including semantic segmentation, object detection, and image classification. Many deep learning-based techniques have been used to segment brain tumors, and the results are encouraging. Existing studies propose solutions for brain tumor segmentation with large computing resources. Our goal is to minimize computational time. We first segment the tumor region on the basis of which we crop the images. Then sent to networks for accurate and fast segmentation of sub-regions.\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = FAISS.from_documents(documents=docs ,embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"vectorstore.pkl\", \"wb\") as f:\n",
    "    pickle.dump(vectordb, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Langchain Prompting Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"vectorstore.pkl\", \"rb\") as f:\n",
    "    my_vector_database = pickle.load(f)\n",
    "\n",
    "retriever = my_vector_database.as_retriever(search_kwargs={\"k\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['context', 'input'] template='\\nYou are a helpful AI assistant.\\nAnswer based on the context provided. \\ncontext: {context}\\ninput: {input}\\nanswer:\\n'\n",
      "\n",
      "Input Variables:  ['context', 'input']\n",
      "\n",
      "Prompt Template:  \n",
      "You are a helpful AI assistant.\n",
      "Answer based on the context provided. \n",
      "context: {context}\n",
      "input: {input}\n",
      "answer:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"\n",
    "You are a helpful AI assistant.\n",
    "Answer based on the context provided. \n",
    "context: {context}\n",
    "input: {input}\n",
    "answer:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "print(prompt)\n",
    "print(\"\\nInput Variables: \", prompt.input_variables)\n",
    "print(\"\\nPrompt Template: \", prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_docs_chain = create_stuff_documents_chain(llm, prompt)\n",
    "retrieval_chain = create_retrieval_chain(retriever, combine_docs_chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Contextural Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "User Query:  Who did a thesis based on emotion detection and what was the title of the thesis, and who was the supervisor?\n",
      "Model Response:  **Muhammad Farrukh Bashir** did a thesis based on emotion detection and the title of the thesis was \"Emotion detection from Urdu text\". His supervisor was **Dr. Waseem Shahzad**.\n"
     ]
    }
   ],
   "source": [
    "query = \"Who did a thesis based on emotion detection and what was the title of the thesis, and who was the supervisor?\"\n",
    "response = retrieval_chain.invoke({ \"input\": query })\n",
    "\n",
    "print(\"\\n\\nUser Query: \", query)\n",
    "print(\"Model Response: \", response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Deep Neural Network Based Detection of Wmotion in NL \\n\\nAdil Majeed (MS-CS)\\nSupervisor: Dr. Hassan Mujtaba\n",
      "https://drive.google.com/file/d/1p_akfJpKNPD5Hn8mcyubSQELWpphvRKb/view?usp=sharing\n",
      "Emotion detection is playing a very important role in our life. People express their emotions in different ways i.e face expression, gestures, speech, and text. This research focuses 00 detecting emotions from the Roman Urdu text. Previously, A lot of work has been done on different languages for emotion detection but there is limited work done in Roman Urdu. Therefore, there is a need to explore Roman Urdu as it is the most widely used language on social media platforms for communication. One major issue for the Roman Urdu is the absence of benchmark corpora for emotion detection from text because language assets are essential for different natural language process-ing (NIL') tasks. There are many useful applications of the emotional analysis of a text such as improving the quality of products, dialog systems, investment trends, men-tal health. In this research, to focus on the emotional polarity of the Roman Urdu sentence we develop a comprehensive corpus of 18k sentences that are gathered from different domains and annotate it with six different classes. We also proposed an en-semble model for emotion detection from the Roman Urdu text. Our proposed model is based on LSTM (Long short-term memory) and CNN (Convolutional neural net-work) feature learners. We applied different baseline algorithms like LSTM, Adaboost, XGboost, MLI, KNN, Decision tree, SVM, and Random Forest on our corpus. After experimentation and evaluation, the results showed that our model achieves better F-measure score than LSTM, KNN, SVM, Adaboost, XGboost, MLP, Decision tree, and Random Forest.\n",
      "\n",
      "\n",
      "\n",
      "Aspect Feature Based Opinion Mining Using Deep Neural Network\\n\\nRabail Zahid (MS-CS)\\nSupervisor: Dr. Hasan Mujtaba\n",
      "https://drive.google.com/file/d/1VdmHpjSCoL0v2jnroHjK5M8vtCQW4qf7/view?usp=sharing\n",
      "Social media, today, demonstrates the rapid growth of modern society as it becomes the main platform for Internet users to communicate and express themselves. Now a days it is impossible to imagine our lives without gadgets like computers, smart-phones, lap- tops, and tablets. People around the world, use many devices and resources to access the Internet, set up social networks, conduct online business, e-commerce, e-surveys, etc. Currently, social media is not only a technology that provides information to consumers, but it also encourages users to connect and share their views and perspectivesS. It leads to an increase in inspiration towards Opinion Mining (OM), which is important for both customers and companies. Individuals like to see the opinions provided by other customers about a particular product or a service. Companies need to analyze their customer's feedback to strengthen their business decisions. This work proposes a novel approach Aspect-Feature-Based Opinion Mining Using Deep Neural Network. The proposed algorithm will be able to extract significant features from reviews. These features are then used for Aspect Category Detection which could be beneficial for market research and product enhancement. We normalized our dataset for tagging nouns and adjectives. It helps us in finding the aspects from the review. Our proposed framework tackles the problem by using Word2vec and glove embedding together with CNN and attention. Our methodology provides better outcomes than other methods used for this purpose. The results demonstrate 60% F1-score for aspect detection and80% for aspect-based polarity.\\n\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "Emotion detection from Urdu text \\n\\n\\nMuhammad Farrukh Bashir (MS-CS)\\nSupervisor: Dr. Waseem Shahzad\n",
      "https://drive.google.com/file/d/1jNe0xeFRM2lh4T1zkuk2NkSxKRCRXfiY/view?usp=sharing\n",
      "Emotion Detection (ED) plays an important role in finding peoples interest in any field. A human can use gestures, facial expressions, speech and texts to describe their emotions. A lot of research work has been done to detect emotions from the textual data in English and other languages. But due to unavailability of the labeled corpus, emotion classification has not been explored in the Urdu language to the best of my knowledge. In this thesis, we propose a new technique for the classification of emotions in the Urdu language using Long Short Term Memory (LSTM). We have also created a diverse dataset of sentences and paragraphs based of ED and labelled it. This is a multi-class data set and has six classes. We have performed an extensive experimentation to check the worth of proposed technique using state of the art performances measures including F-Measure, accuracy, precision etc. The experimental results showed that the proposed technique performed better than the other state of the art techniques.\n",
      "\n",
      "\n",
      "\n",
      "Balanced quantum inspired evolutionary algorithm\\n\\n\\nMuhammad Shahid Sharif (MS-CS)\\nSupervisor: Dr. Hasan Mujtaba\n",
      "https://drive.google.com/file/d/1fRbkphkJd9u4nnmL6Tu7llpSvMsjHG68/view?usp=sharing\n",
      "Quantum evolutionary algorithms promised great improvement in fast convergence and solution quality due to their properties like qubit representation, superposition and entanglement. Despite these benefits, pre-mature convergence is the main issue of QEA because QEA uses the only best individual to update quantum population. In this thesis, we have introduced a new way to update the quantum population of QEA to avoid premature convergence. Best individual and worst individual are used for up-dating the population for balanced exploration and exploitation. The balance between exploration and exploitation maintains enough diversity in population to avoid pre-mature convergence. Knapsack problem and lane reservation problem are selected for experiments and testing of BQEA. The knapsack problem is about an optimal selection of items from a repository to maximize profit while keeping the total weight under the limit. Lane reservation problem aims at optimal selection and reservation of lanes that minimize the negative traffic impact. Experiments are performed on different sizes of the knapsack problem and BQEA is performing better than the state of the art QEA's.\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "Contact Aware emotion detection in texual conversation\\n\\nSyed Ali Imran (MS-CS)\\nSupervisor: Dr. Omer Ishaq \\n\n",
      "https://drive.google.com/file/d/1IurMZwSOb8rJGnUsdFX0-yVFZI5V1rFI/view?usp=sharing\n",
      "Analysis on the basis of emotions is quite exasperating challenge for Natural Language Processing. Finding the emotions of a person in a conversation such as happy, sad and angry is difficult and becomes more challenging when we have to consider context and background of the whole conversation instead of just one sentence. Mapping and keeping track of long sentence dependencies is unsuitable and challenging even for methods like neural network, problems like vanishing gradients make it strenuous for coming up with a good classifier. We propose a method based on transformers, self attention mechanism and bert base, for the classification of emotion during a textual conversation. In our approach we extended pair to pair relationship between words using the attention mechanism. In our research, we experimented with different networks, and parameters to find the best result. We researched, with respect to embedding representations, attention mechanism, pre-processing and network architecture. Our proposed method, which extends attention mechanism, was able to beat the state of the art.\n",
      "\n",
      "\n",
      "\n",
      "Protein Secondary Structure prediction\\nusing Sequential Features\\n\\nHamza Mustafa Alvi (MS-CS)\\nSupervisor: Dr. Hammad Naveed\n",
      "https://drive.google.com/file/d/1itk7kMjs5aEbKSwc-Cndtzaognkn0Ogb/view?usp=sharing\n",
      "Secondary structure of protein is used in studying the 3D structure of the protein. 3D structure is helpful in studying the function of protein, which helps in designing the drugs that bind to specific proteins. Most of the existing studies only use sequence and position specific scoring matrix (PSSM) to predict the secondary structure or they use deep learning models to capture local and global context of amino acids from the sequences. A deep learning model can effectively capture local or global context, it canâ€™t capture both effectively. To address this problem, we used local context of amino acid as motifs and anti-motifs in deep learning models. Class-specific motifs and anti-motifs alone produced 43.8% Q3 accuracy. Thus incorporating this information will lead to better results. Moreover, we used pre-trained embeddings of amino acids along with the sequence and PSSM as input features for the deep learning model. The model using pre-trained embeddings reached to a Q8 accuracy of 71.7%. Most of the recent studies used deep learning models that include convolutional neural networks (CNN) and/or recurrent neural networks (RNN). In contrast to these, we have used attention based RNN model that incorporates the importance of residues while making prediction. The attention based LSTM produced a Q8 accuracy of 68.5%. In future, we will combine all the above mentioned features to improve the performance of proposeddeep learning based models.\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "54\n",
      "Noor Ul Ain\\n\\nElevated Quantity and Quality of EMA Responses Via Gamification\n",
      "https://drive.google.com/file/d/1NBCTIPWxZDE5WZZnURgljdoQ7-J40N6a/view?usp=sharing\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "67\n",
      "21I-2392 Nadia Bashir\\n\\n\\nQAEAR -LSTM: An Automated Quality Concerns Identification Approach for App Reviews\\n Using Deep Learning Models\n",
      "https://drive.google.com/file/d/1zk09-fHRgc7qrZqnsCPG-qB0HcWZd3j3/view?usp=sharing\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# context docs passed to the model\n",
    "\n",
    "context_docs = response[\"context\"]\n",
    "for doc in context_docs:\n",
    "    print(\"-\"*50)\n",
    "    print(doc.page_content)\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtual",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
